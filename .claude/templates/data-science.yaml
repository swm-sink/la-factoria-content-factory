# Data Science ML Platform Adaptation Pattern
# Optimized for data science teams working with ML pipelines and notebooks

adaptation_pattern:
  metadata:
    name: "Data Science ML Platform"
    description: "Optimized for data science teams working with ML pipelines and notebooks"
    author: "Claude Code Community" 
    version: "1.0"
    created: "2025-07-28"
  
  configuration:
    placeholders:
      DOMAIN: "data-science"
      TECH_STACK: "Python+Jupyter+TensorFlow+Spark"
      TEAM_SIZE: "medium"
      WORKFLOW_TYPE: "experimental"
      PRIMARY_LANGUAGE: "Python"
      TESTING_FRAMEWORK: "pytest+hypothesis"
      CI_CD_PLATFORM: "GitLab CI"
      DEPLOYMENT_TARGET: "Kubernetes+GCP"
      DATABASE_TYPE: "PostgreSQL+BigQuery"
      API_STYLE: "REST"
      SECURITY_LEVEL: "standard"
      PERFORMANCE_PRIORITY: "optimized"
      USER_BASE: "internal"
  
  command_selection:
    include:
      categories:
        - "core"
        - "analysis"
        - "testing"
        - "database"
      commands:
        - "/query"
        - "/analyze-data"
        - "/notebook-run"
        - "/dataset-prep"
        - "/model-train"
        - "/model-evaluate"
        - "/pipeline"
        - "/test-data"
        - "/monitor-metrics"
        - "/experiment-track"
    exclude:
      commands:
        - "/ui-test"
        - "/frontend-build"
  
  domain_specific:
    commands:
      - name: "/notebook-run"
        description: "Execute Jupyter notebooks with parameters"
        usage: "/notebook-run experiment.ipynb --params dataset=train"
      - name: "/dataset-prep"
        description: "Prepare and validate datasets for training"
        usage: "/dataset-prep raw_data.csv --split 80/20 --stratify"
      - name: "/model-train"
        description: "Train ML models with experiment tracking"
        usage: "/model-train --algorithm xgboost --track-mlflow"
      - name: "/experiment-track"
        description: "Track experiments with MLflow or similar"
        usage: "/experiment-track --name \"feature_engineering_v2\""
  
  customizations:
    settings:
      notebooks:
        kernel: "python3"
        extensions: "nbextensions,jupyterlab"
        git_integration: "nbdime"
      compute:
        gpu_support: true
        distributed: "spark,dask"
    
    workflows:
      model_development:
        steps:
          - "/dataset-prep --validate"
          - "/notebook-run explore.ipynb"
          - "/model-train --cross-validate"
          - "/model-evaluate --test-set"
          - "/experiment-track --compare"
      
      production_pipeline:
        steps:
          - "/pipeline data-ingestion"
          - "/pipeline feature-engineering"
          - "/pipeline model-inference"
          - "/monitor-metrics --model-drift"
  
  success_metrics:
    setup_time: "10 minutes"
    commands_adapted: 52
    readiness_score: "89%"
    notebook_integration: "complete"
    time_saved: "15 months"
  
  notes:
    - "Includes Jupyter notebook integration"
    - "ML experiment tracking built-in"
    - "Supports both batch and streaming data"
    - "GPU-optimized compute configurations"
    - "Reproducible research focus"